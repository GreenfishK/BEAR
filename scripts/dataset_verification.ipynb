{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df01354c",
   "metadata": {},
   "source": [
    "This script assumes that you have following data and directories:\n",
    "* \"/.BEAR/rawdata-bearb/hour/alldata.IC.nt/\"\n",
    "* \"/.BEAR/rawdata-bearb/hour/alldata.CB.nt/\"\n",
    "\n",
    "In alldata.IC.nt and alldata.CB.nt you should have the independent copies (IC) and change sets (CB) from the BEAR-B hourly datasets.\n",
    "BEAR webpage: https://aic.ai.wu.ac.at/qadlod/bear.html\n",
    "on the webpage go to Description of the dataset/Get the dataset/hour and download alldata.IC.nt.tar.gz and \talldata.CB.nt.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9dd537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# conda install -c conda-forge sparqlwrapper\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, Wrapper, GET\n",
    "\n",
    "pd.options.display.max_columns=300\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd84e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_df(result: Wrapper.QueryResult) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    :param result:\n",
    "    :return: Dataframe\n",
    "    \"\"\"\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "    def format_value(res_value):\n",
    "        value = res_value[\"value\"]\n",
    "        lang = res_value.get(\"xml:lang\", None)\n",
    "        datatype = res_value.get(\"datatype\", None)\n",
    "        if lang is not None:\n",
    "            value += \"@\" + lang\n",
    "        if datatype is not None:\n",
    "            value += \" [\" + datatype + \"]\"\n",
    "        return value\n",
    "\n",
    "    results = result.convert()\n",
    "\n",
    "    column_names = []\n",
    "    for var in results[\"head\"][\"vars\"]:\n",
    "        column_names.append(var)\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    values = []\n",
    "    for r in results[\"results\"][\"bindings\"]:\n",
    "        row = []\n",
    "        for col in results[\"head\"][\"vars\"]:\n",
    "            if col in r:\n",
    "                result_value = format_value(r[col])\n",
    "            else:\n",
    "                result_value = None\n",
    "            row.append(result_value)\n",
    "        values.append(row)\n",
    "    df = df.append(pd.DataFrame(values, columns=df.columns))\n",
    "\n",
    "    return df\n",
    "\n",
    "def number_of_triples(version: int):\n",
    "    ic0_ds_path = str(Path.home()) + \"/.BEAR/rawdata-bearb/hour/alldata.IC.nt/00{0}.nt\".format(str(version).zfill(4))\n",
    "    ic0_list = []\n",
    "    with open(ic0_ds_path, \"r\") as ic0:\n",
    "        for triple in ic0:\n",
    "            tr_array = triple[:-2].split(\" \", 2)\n",
    "            if len(tr_array) == 3:\n",
    "                ic0_list.append(tr_array)\n",
    "\n",
    "    ic0_df = pd.DataFrame(ic0_list, columns=['s', 'p', 'o'])\n",
    "    return len(ic0_df)\n",
    "\n",
    "\n",
    "def cb_to_df(version: int, added_or_deleted: str = \"added\"):\n",
    "    \"\"\"\n",
    "    version: the actual version. E.g. for triples added between v1 and v2 (data-added_1-2.nt) 2 would\n",
    "    be the parameter value.\n",
    "    \"\"\"\n",
    "\n",
    "    version_prev = version - 1\n",
    "    if version == 1:\n",
    "        return \"This is the initial version. There is no change set previous to this version. Choose are version \" \\\n",
    "               \"higher than 1 and lower than 1300.\"\n",
    "    cb0_ds_path = str(Path.home()) + \"/.BEAR/rawdata-bearb/hour/alldata.CB.nt/data-{0}_{1}-{2}.nt\".\\\n",
    "        format(added_or_deleted, version_prev, version)\n",
    "    cb0_list = []\n",
    "    with open(cb0_ds_path, \"r\") as ic0:\n",
    "        for triple in ic0:\n",
    "            tr_array = triple[:-2].split(\" \", 2)\n",
    "            if len(tr_array) == 3:\n",
    "                cb0_list.append(tr_array)\n",
    "\n",
    "    cb0_df = pd.DataFrame(cb0_list, columns=['s', 'p', 'o'])\n",
    "    return cb0_df\n",
    "\n",
    "\n",
    "def ic_to_df(version: int):\n",
    "    ic0_ds_path = str(Path.home()) + \"/.BEAR/rawdata-bearb/hour/alldata.IC.nt/00{0}.nt\".format(str(version).zfill(4))\n",
    "    ic0_list = []\n",
    "    with open(ic0_ds_path, \"r\") as ic0:\n",
    "        for triple in ic0:\n",
    "            tr_array = triple[:-2].split(\" \", 2)\n",
    "            if len(tr_array) == 3:\n",
    "                ic0_list.append(tr_array)\n",
    "\n",
    "    ic0_df = pd.DataFrame(ic0_list, columns=['s', 'p', 'o'])\n",
    "    return ic0_df\n",
    "\n",
    "\n",
    "def check_ic_cb_consistency():\n",
    "    l = []\n",
    "    for i in range(2, 1300):\n",
    "        check_flag = False\n",
    "        if len(ic_to_df(i - 1)) + len(cb_to_df(i)) - len(cb_to_df(i, \"deleted\")) == len(ic_to_df(i)):\n",
    "            check_flag = True\n",
    "        l.append([i, len(ic_to_df(i)), len(ic_to_df(i-1)), len(cb_to_df(i)), len(cb_to_df(i, \"deleted\")),\n",
    "                   len(cb_to_df(i)) - len(cb_to_df(i, \"deleted\")), len(ic_to_df(i)) - len(ic_to_df(i-1)),\n",
    "                   check_flag])\n",
    "    df = pd.DataFrame(l, columns=['version', 'cnt_trpls_IC', 'cnt_trpls_IC_prev', 'cnt_added_trpls',\n",
    "                                  'cnt_deleted_trpls', 'cnt_trpls_added_net',\n",
    "                                  'cnt_trpls_diff_ICs', 'flag_changes_consistent?'])\n",
    "    return df\n",
    "\n",
    "def check_ic_tb_consistency(get_endpoint: str):\n",
    "    # TODO: check whether the ICs and individual versions \n",
    "    # in alldata.TB_star.ttl are consistent with each other\n",
    "\n",
    "    df_checks = pd.DataFrame(columns=['version', 'cnt_trpls_ic', 'cnt_trpls_tb', 'check_flag'])\n",
    "    \n",
    "    for version in range (1, 1300):\n",
    "        # TB\n",
    "        sparql = SPARQLWrapper(get_endpoint)\n",
    "        sparql.setQuery(\"\"\"     \n",
    "            select ?s ?p ?o\n",
    "            where {{\n",
    "                GRAPH ?g {{\n",
    "                    ?s ?p ?o .\n",
    "                }}\n",
    "            filter (contains(str(?g), \"v{0}\") || contains(str(?g), \"_{0}\")) \n",
    "            }}\n",
    "        \"\"\".format(version-1))\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        results = sparql.query()\n",
    "\n",
    "        # IC\n",
    "        df_ic = ic_to_df(version)\n",
    "        cnt_trpls_ic = len(df_ic)\n",
    "\n",
    "        df_tb = _to_df(results)\n",
    "        cnt_trpls_tb = len(df_tb)\n",
    "\n",
    "        df_checks.loc[len(df_checks)] = [version, cnt_trpls_ic, cnt_trpls_tb, cnt_trpls_ic==cnt_trpls_tb]\n",
    "    \n",
    "    return df_checks\n",
    "\n",
    "\n",
    "def print_stats(version: int):\n",
    "    print(\"Number of triples in IC version {0}: {1}\".format(version, len(ic_to_df(version))))\n",
    "    print(\"Number of triples in previous IC version {0}: {1}\".format(version-1, len(ic_to_df(version-1))))\n",
    "    print(\"Number of added triples in version {0} compared to previous version: {1}\".\n",
    "          format(version, len(cb_to_df(version))))\n",
    "    print(\"Number of deleted triples in version {0} compared to previous version: {1}\".\n",
    "          format(version, len(cb_to_df(version, \"deleted\"))))\n",
    "\n",
    "    check_flag = False\n",
    "    if len(ic_to_df(version-1)) + len(cb_to_df(version)) - len(cb_to_df(version, \"deleted\")) == len(ic_to_df(version)):\n",
    "        check_flag = True\n",
    "\n",
    "    print(\"Check whether the change numbers reflect the difference between two ICs: {0} + {1} - {2} = {3}: Equation {4}\".\n",
    "          format(len(ic_to_df(version-1)), len(cb_to_df(version)), len(cb_to_df(version, \"deleted\")),\n",
    "                 len(ic_to_df(version)), check_flag))\n",
    "\n",
    "    df1 = ic_to_df(version-1)\n",
    "    cb_add = cb_to_df(version)\n",
    "    cb_del = cb_to_df(version, \"deleted\")\n",
    "    df_diff1 = cb_add.merge(cb_del, on=['s', 'p', 'o'], how=\"inner\")\n",
    "    df1 = df1.merge(cb_add, on=['s', 'p', 'o'], how=\"inner\")\n",
    "    assert len(df1) == len(df_diff1)\n",
    "\n",
    "    print(\"Number of triples that have been deleted and added again (or vice versa) \"\n",
    "          \"in version {0} compared to previous version: {1}\".format(version, len(df_diff)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "432054a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verify that the number of triples in version 1 is 33502\n",
      "Verify that the number of triples in version 1299 is 43907\n",
      "Verify that all added triples between version 1 and 2 are included in version 2\n",
      "Verify that all triples that are included in version 1 and version 2 are also reflected in the intersection of the added and deleted change sets. Thus, they must have been deleted and then added again.\n",
      "Verify that the deleted triples between version 1 and version 2 are included in version 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Verify that the number of triples in version 1 is 33502\")\n",
    "assert number_of_triples(1) == 33502\n",
    "\n",
    "print(\"Verify that the number of triples in version 1299 is 43907\")\n",
    "assert number_of_triples(1299) == 43907\n",
    "\n",
    "print(\"Verify that all added triples between version 1 and 2 are included in version 2\")\n",
    "v2_df = ic_to_df(2)\n",
    "v1_v2_cb = cb_to_df(2)\n",
    "df = v2_df.merge(v1_v2_cb, on=['s', 'p', 'o'], how=\"inner\")\n",
    "assert len(df) == len(v1_v2_cb)\n",
    "\n",
    "\n",
    "print(\"Verify that all triples that are included in version 1 and version 2 are also reflected in the \"\n",
    "      \"intersection of the added and deleted change sets. Thus, they must have been deleted and then added again.\")\n",
    "# There are some triples that have been deleted and then added again between version 1 and 2\n",
    "v1_df = ic_to_df(1)\n",
    "v1_v2_cb = cb_to_df(2)\n",
    "v1_v2_cb_del = cb_to_df(2, \"deleted\")\n",
    "df_diff = v1_v2_cb.merge(v1_v2_cb_del, on=['s', 'p', 'o'], how=\"inner\")\n",
    "df = v1_df.merge(v1_v2_cb, on=['s', 'p', 'o'], how=\"inner\")\n",
    "assert len(df) == len(df_diff)\n",
    "\n",
    "\n",
    "print(\"Verify that the deleted triples between version 1 and version 2 are included in version 1\")\n",
    "v1_df = ic_to_df(1)\n",
    "v1_v2_cb_del = cb_to_df(2, \"deleted\")\n",
    "df = v1_df.merge(v1_v2_cb_del, on=['s', 'p', 'o'], how=\"inner\")\n",
    "assert len(df) == len(v1_v2_cb_del)\n",
    "\n",
    "# diff set between v1 and v2\n",
    "# v1_df = ic_to_df(1)\n",
    "# v2_df = ic_to_df(2)\n",
    "# df_diff = pd.concat([v1_df, v2_df]).drop_duplicates(keep=False)\n",
    "# df_1 = df_diff.merge(v1_v2_cb, on=['s', 'p', 'o'], how=\"inner\")\n",
    "# df_2 = df_diff.merge(v1_v2_cb_del, on=['s', 'p', 'o'], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49678e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_ic_cb_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963fdf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local SPARQL endpoint from GraphDB free. Needs to be installed and the alldata.TB.nq dataset imported into a new \n",
    "# repository 'BEAR-B_hourly_TB'\n",
    "check_ic_tb_consistency(get_endpoint=\"http://ThinkPad-T14s-FK:7200/repositories/BEAR-B_hourly_TB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2082cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
