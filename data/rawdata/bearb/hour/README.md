* Download the BEAR-B hour-datasets from the [BEAR webpage](https://aic.ai.wu.ac.at/qadlod/bear.html) (4 files in section 3.BEAR-B/description of the dataset/get the dataset) and copy them into ~/home/.BEAR/rawdata-bearb/hour. If you followed the steps, this directory should exist by now.
* Extract the datasets from their .gz packages. Also extract all sub .gz packages.
* Rename allData.nq to alldata.TB.nq.
* Create the alldata.TB_star.ttl dataset by using the script provided [here](https://github.com/GreenfishK/BEAR/blob/master/scripts/build_tb_rdf_star_dataset.py). This script first computes changesets from the ICs and stores them into the alldata.CB_computed.nt directory. From the initial IC alldata.IC.nt/000001.nt and the change sets it creates the single-filed RDF*-based TB dataset. This dataset includes all of the 1299 versions where each version is a set of triples with the same creation timestamp (valid_from). The timestamps do not reflect the original timestamps but are artificially constructed with one second difference between each version. Triples that were deleted and therefore not existent in a specific version anymore are annotated with a deletion timestamp (valid_until).
